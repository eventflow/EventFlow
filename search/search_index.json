{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":"<p>EventFlow is a basic CQRS+ES framework designed to be easy to use.</p> <p>Have a look at our getting started guide, the do\u2019s and don\u2019ts, and the FAQ.</p> <ul> <li> The source code is available on GitHub and provided under the MIT license.</li> <li> To engage with the community, please join our Discord server.</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Easy to use: Designed with sensible defaults and implementations that make it easy to create an example application</li> <li>Highly configurable and extendable: EventFlow uses interfaces for every part of its core, making it easy to replace or extend existing features with custom implementations.</li> <li>No use of threads or background workers</li> <li>MIT licensed: Easy to understand and use license for enterprise</li> </ul> <p>Example</p> <p>Documentation is still in progress for v1</p> <p>If you have any suggestions for the documentation, even if it's just a typo, please create an issue or a pull request. Improvements to the documentation are always welcome.</p> <p>Useful links for updating the documentation:</p> <ul> <li>https://squidfunk.github.io/mkdocs-material/reference/</li> </ul>"},{"location":"getting-started/","title":"Getting started","text":"<p>Initializing EventFlow always starts with a call to the <code>AddEventFlow(ef =&gt; {})</code> extension method as this performs the initial bootstrap and starts the fluent configuration API.</p> <pre><code>var services = new ServiceCollection();\nservices.AddEventFlow(ef =&gt; ef.AddDefaults(typeof(Startup).Assembly));\nusing var serviceProvider = services.BuildServiceProvider();\n</code></pre> <p>The above line configures several important defaults:</p> <ul> <li>In-memory event store</li> <li>A \"null\" snapshot store, that merely writes a warning if used (no need to do anything before going to production if you aren't planning to use snapshots)</li> <li>And lastly, default implementations of all the internal parts of EventFlow</li> </ul> <p>Tip</p> <p>If you are setting up small tests, it's possible to use the shorthand <code>EventFlowOptions.New</code> to get an already initialized <code>IServiceCollection</code> instance that can be used for further configuration. This should only be used for testing and not in production code.</p> <p>To start using EventFlow, a domain must be configured which consists of the following parts:</p> <ul> <li>Aggregate</li> <li>Aggregate identity</li> <li>Aggregate events</li> <li>Commands and command handlers (optional, but highly recommended)</li> </ul> <p>In addition to the above, EventFlow provides several optional features. Whether or not these features are utilized depends on the application in which EventFlow is used.</p> <ul> <li>Read models</li> <li>Subscribers</li> <li>Event upgraders</li> <li>Queries</li> <li>Jobs</li> <li>Snapshots</li> <li>Sagas</li> <li>Metadata providers</li> </ul>"},{"location":"getting-started/#example-application","title":"Example application","text":"<p>The example application includes one of each of the required parts: aggregate, event, aggregate identity, command, and a command handler. Further down we will go through each of the individual parts.</p> <p>All classes created for the example application are prefixed with <code>Example</code>.</p> <pre><code>public class ExampleTests\n{\n  [Test]\n  public async Task ExampleTest()\n  {\n    // Arrange\n    var services = new ServiceCollection();\n    services.AddEventFlow(ef =&gt; ef\n      .AddDefaults(typeof(ExampleAggregate).Assembly)\n      .UseInMemoryReadStoreFor&lt;ExampleReadModel&gt;());\n    using var serviceProvider = services.BuildServiceProvider();\n\n    var commandBus = serviceProvider.GetRequiredService&lt;ICommandBus&gt;();\n    var queryProcessor = serviceProvider.GetRequiredService&lt;IQueryProcessor&gt;();\n    var exampleId = ExampleId.New;\n\n    // Act\n    await commandBus.PublishAsync(new ExampleCommand(exampleId, 42), CancellationToken.None)\n      .ConfigureAwait(false);\n    var exampleReadModel = await queryProcessor.ProcessAsync(new ReadModelByIdQuery&lt;ExampleReadModel&gt;(exampleId), CancellationToken.None)\n      .ConfigureAwait(false);\n\n    // Assert\n    exampleReadModel.MagicNumber.Should().Be(42);\n  }\n}\n</code></pre> <p>The above example publishes the <code>ExampleCommand</code> to the aggregate with the <code>exampleId</code> identity with the magical value of <code>42</code>. After the command has been published, the accompanying read model <code>ExampleReadModel</code> is fetched and we verify that the magical number has reached it.</p> <p>During the execution of the example application, a single event is emitted and stored in the in-memory event store. The JSON for the event is shown here.</p> <pre><code>{\n  \"MagicNumber\": 42\n}\n</code></pre> <p>The event data itself is straightforward as it is merely the JSON serialization of an instance of the type <code>ExampleEvent</code> with the value we defined. A bit more interesting is the metadata that EventFlow stores alongside the event, which is used by the EventFlow event store.</p> <pre><code>{\n  \"timestamp\": \"2016-11-09T20:56:28.5019198+01:00\",\n  \"aggregate_sequence_number\": \"1\",\n  \"aggregate_name\": \"ExampleAggregate\",\n  \"aggregate_id\": \"example-c1d4a2b1-c75b-4c53-ae44-e67ee1ddfd79\",\n  \"event_id\": \"event-d5622eaa-d1d3-5f57-8023-4b97fabace90\",\n  \"timestamp_epoch\": \"1478721389\",\n  \"batch_id\": \"52e9d7e9-3a98-44c5-926a-fc416e20556c\",\n  \"source_id\": \"command-69176516-07b7-4142-beaf-dba82586152c\",\n  \"event_name\": \"example\",\n  \"event_version\": \"1\"\n}\n</code></pre> <p>All the built-in metadata is available on each instance of <code>IDomainEvent&lt;,,&gt;</code>, which is accessible from event handlers for e.g. read models or subscribers. It is also possible to create your own metadata providers or add additional EventFlow built-in providers as needed.</p>"},{"location":"getting-started/#aggregate-identity","title":"Aggregate identity","text":"<p>The aggregate ID in EventFlow is represented as a value object that inherits from the <code>IIdentity</code> interface. You can provide your own implementation, but EventFlow provides a convenient implementation that will suit most needs. Be sure to read the section about the Identity&lt;&gt; class for details on how to use it.</p> <p>For our example application, we use the built-in class, which makes the implementation very simple.</p> <pre><code>public class ExampleId : Identity&lt;ExampleId&gt;\n{\n  public ExampleId(string value) : base(value) { }\n}\n</code></pre>"},{"location":"getting-started/#aggregate","title":"Aggregate","text":"<p>Now we'll take a look at the <code>ExampleAggregate</code>. It is rather simple as the only thing it can do is apply the magic number once.</p> <pre><code>public class ExampleAggregate : AggregateRoot&lt;ExampleAggregate, ExampleId&gt;,\n  IEmit&lt;ExampleEvent&gt;\n{\n  private int? _magicNumber;\n\n  public ExampleAggregate(ExampleId id) : base(id) { }\n\n  public IExecutionResult SetMagicNumber(int magicNumber)\n  {\n    if (_magicNumber.HasValue)\n    {\n      return ExecutionResult.Failed(\"Magic number already set\");\n    }\n\n    Emit(new ExampleEvent(magicNumber));\n    return ExecutionResult.Success();\n  }\n\n  public void Apply(ExampleEvent aggregateEvent)\n  {\n    _magicNumber = aggregateEvent.MagicNumber;\n  }\n}\n</code></pre> <p>Be sure to read the section on aggregates to get all the details right. For now, the most important thing to note is that the state of the aggregate (updating the <code>_magicNumber</code> variable) happens in the <code>Apply(ExampleEvent)</code> method. This is the event sourcing part of EventFlow in effect. As state changes are only saved as events, mutating the aggregate state must happen in such a way that the state changes are replayed the next time the aggregate is loaded. EventFlow has a set of different approaches that you can select from. In this example, we use the <code>Apply</code> methods as they are the simplest.</p> <p>Info</p> <p>The <code>Apply(ExampleEvent)</code> is invoked by the <code>Emit(...)</code> method, so after the event has been emitted, the aggregate state has changed.</p> <p>The <code>ExampleAggregate</code> exposes the <code>SetMagicNumber(int)</code> method, which is used to expose the business rules for changing the magic number. If the magic number hasn't been set before, the event <code>ExampleEvent</code> is emitted and the aggregate state is mutated.</p> <p>If the magic number was changed, we return a failed <code>IExecutionResult</code> with an error message. Returning a failed execution result will make EventFlow disregard any events the aggregate has emitted.</p> <p>If you need to return something more useful than a <code>bool</code> in an execution result, merely create a new class that implements the <code>IExecutionResult</code> interface and specify the type as generic arguments for the command and command handler.</p> <p>Tip</p> <p>While possible, do not use the execution results as a method of reading values from the aggregate, that's what the <code>IQueryProcessor</code> and read models are for.</p>"},{"location":"getting-started/#event","title":"Event","text":"<p>Next up is the event which represents something that has happened in our domain. In this example, it's merely that some magic number has been set. Normally these events should have a really, really good name and represent something in the ubiquitous language for the domain.</p> <pre><code>[EventVersion(\"example\", 1)]\npublic class ExampleEvent : AggregateEvent&lt;ExampleAggregate, ExampleId&gt;\n{\n  public ExampleEvent(int magicNumber)\n  {\n    MagicNumber = magicNumber;\n  }\n\n  public int MagicNumber { get; }\n}\n</code></pre> <p>We have applied the <code>[EventVersion(\"example\", 1)]</code> to our event, marking it as the <code>example</code> event version <code>1</code>, which directly corresponds to the <code>event_name</code> and <code>event_version</code> from the metadata stored alongside the event mentioned. The information is used by EventFlow to tie the name and version to a specific .NET type.</p> <p>Warning</p> <p>Even though using the <code>EventVersion</code> attribute is optional, it is highly recommended. EventFlow will infer the information if it isn't provided, thus making it vulnerable to type renames among other things.</p> <p>Danger</p> <p>Once you have aggregates in your production environment that have emitted an event, you should never change the .NET implementation of the event! You can deprecate it, but you should never change the type or the data stored in the event store. If the event type is changed, EventFlow will not be able to deserialize the event and can produce unexpected results when reading old aggregates.</p> <p>To handle changes to events, you can use event upgraders.</p>"},{"location":"getting-started/#command","title":"Command","text":"<p>Commands are the entry point to the domain and if you remember from the example application, they are published using the <code>ICommandBus</code> as shown here.</p> <pre><code>await commandBus.PublishAsync(new ExampleCommand(exampleId, 42), CancellationToken.None)\n  .ConfigureAwait(false);\n</code></pre> <p>In EventFlow, commands are simple value objects that merely house the arguments for the command execution. All commands implement the <code>ICommand&lt;,&gt;</code> interface, but EventFlow provides an easy-to-use base class that you can use.</p> <pre><code>public class ExampleCommand : Command&lt;ExampleAggregate, ExampleId&gt;\n{\n  public ExampleCommand(ExampleId aggregateId, int magicNumber)\n    : base(aggregateId)\n  {\n    MagicNumber = magicNumber;\n  }\n\n  public int MagicNumber { get; }\n}\n</code></pre> <p>A command doesn't do anything without a command handler. In fact, EventFlow will throw an exception if a command doesn't have exactly one command handler registered.</p>"},{"location":"getting-started/#command-handler","title":"Command handler","text":"<p>The command handler provides the glue between the command, the aggregate, and the IoC container as it defines how a command is executed. Typically they are rather simple, but they could contain more complex logic. How much is up to you.</p> <pre><code>public class ExampleCommandHandler : CommandHandler&lt;ExampleAggregate, ExampleId, ExampleCommand&gt;\n{\n  public override Task&lt;IExecutionResult&gt; ExecuteCommandAsync(\n    ExampleAggregate aggregate,\n    ExampleCommand command,\n    CancellationToken cancellationToken)\n  {\n    return Task.FromResult(aggregate.SetMagicNumber(command.MagicNumber));\n  }\n}\n</code></pre> <p>The <code>ExampleCommandHandler</code> in our case here merely invokes the <code>SetMagicNumber</code> on the aggregate and returns the execution result. Remember, if a command handler returns a failed execution result, EventFlow will disregard any events the aggregate has emitted.</p> <p>Warning</p> <p>Everything inside the <code>ExecuteCommandAsync(...)</code> method of a command handler may be executed more than once if there's an optimistic concurrency exception, i.e., something else has happened to the aggregate since it was loaded from the event store and it's therefore automatically reloaded by EventFlow. It is therefore essential that the command handler doesn't mutate anything other than the aggregate.</p>"},{"location":"getting-started/#read-model","title":"Read model","text":"<p>If you ever need to access the data in your aggregates efficiently, it's important that read models are used. Loading aggregates from the event store takes time and it's impossible to query for e.g. aggregates that have a specific value in their state.</p> <p>In our example, we merely use the built-in in-memory read model store. It is useful in many cases, e.g. executing automated domain tests in a CI build.</p> <pre><code>public class ExampleReadModel : IReadModel,\n  IAmReadModelFor&lt;ExampleAggregate, ExampleId, ExampleEvent&gt;\n{\n  public int MagicNumber { get; private set; }\n\n  public Task ApplyAsync(\n    IReadModelContext context,\n    IDomainEvent&lt;ExampleAggregate, ExampleId, ExampleEvent&gt; domainEvent,\n    CancellationToken cancellationToken)\n  {\n    MagicNumber = domainEvent.AggregateEvent.MagicNumber;\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>Notice the <code>IDomainEvent&lt;ExampleAggregate, ExampleId, ExampleEvent&gt; domainEvent</code> argument. It's merely a wrapper around the specific event we implemented earlier. The <code>IDomainEvent&lt;,,&gt;</code> provides additional information, e.g. any metadata stored alongside the event.</p> <p>The main difference between the event instance emitted in the aggregate and the instance wrapped here is that the event has been committed to the event store.</p>"},{"location":"getting-started/#next-steps","title":"Next steps","text":"<p>Although the implementation in this guide enables you to create a complete application, there are several topics that are recommended as next steps.</p> <ul> <li>Read the dos and don'ts section</li> <li>Use value objects to produce cleaner JSON</li> <li>If your application needs to act on an emitted event, create a subscriber</li> <li>Check the configuration to make sure everything is as you would like it</li> <li>Set up a persistent event store using e.g. Microsoft SQL Server</li> <li>Create read models for efficient querying</li> <li>Consider the use of specifications to ease the creation of business rules</li> </ul>"},{"location":"additional/configuration/","title":"Configuration","text":"<p>EventFlow configuration can be done via the <code>.Configure(o =&gt; {})</code> method, which is available on the <code>EventFlowOptions</code> object.</p> <pre><code>using var serviceCollection = new ServiceCollection()\n    // ...\n    .AddEventFlow(e =&gt; e.Configure(o =&gt;\n    {\n        o.IsAsynchronousSubscribersEnabled = true;\n        o.ThrowSubscriberExceptions = true;\n    }))\n    // ...\n    .BuildServiceProvider();\n</code></pre> <p>In this example, we enable asynchronous subscribers and configure EventFlow to throw exceptions for subscriber errors. You can customize the configuration options to suit your needs.</p>"},{"location":"additional/dos-and-donts/","title":"Do's and don'ts","text":"<p>Whenever creating an application that uses CQRS+ES there are several things you need to keep in mind to make it easier and minimize the potential bugs. This guide will give you some details on typical problems and how EventFlow can help you minimize the risk.</p>"},{"location":"additional/dos-and-donts/#business-rules","title":"Business rules","text":""},{"location":"additional/dos-and-donts/#specifications","title":"Specifications","text":"<p>Consider moving complex business rules to specifications. This eases both readability, testability and re-use.</p>"},{"location":"additional/dos-and-donts/#events","title":"Events","text":""},{"location":"additional/dos-and-donts/#produce-clean-json","title":"Produce clean JSON","text":"<p>Make sure that when your aggregate events are JSON serialized, they produce clean JSON as it makes it easier to work with and enables easier deserialization of events in the future.</p> <ul> <li>No type information</li> <li>No hints of value objects, see value objects</li> </ul> <p>Here's an example of good clean event JSON produced from a create user event.</p> <pre><code>{\n  \"Username\": \"root\",\n  \"PasswordHash\": \"1234567890ABCDEF\",\n  \"EMail\": \"root@example.org\"\n}\n</code></pre>"},{"location":"additional/dos-and-donts/#keep-old-event-types","title":"Keep old event types","text":"<p>Keep in mind that you need to keep the event types in your code for as long as these events are in the event source, which in most cases is forever as storage is cheap and information, i.e., your domain events, are expensive.</p> <p>However, you should still clean your code. Have a look at how you can upgrade and version your events for details on how EventFlow supports you in this.</p>"},{"location":"additional/dos-and-donts/#subscribers-and-out-of-order-events","title":"Subscribers and out of order events","text":"<p>Be very careful if aggregates emit multiple events for a single command, subscribers will almost certainly receive these out of order.</p>"},{"location":"additional/faq/","title":"FAQ - frequently asked questions","text":""},{"location":"additional/faq/#how-can-i-ensure-that-only-specific-users-can-execute-commands","title":"How can I ensure that only specific users can execute commands?","text":"<p>You can either replace the implementation of <code>ICommandBus</code> with your own implementation, or add a decorator that adds the authentication logic. </p>"},{"location":"additional/faq/#why-isnt-there-a-global-sequence-number-on-domain-events","title":"Why isn't there a \"global sequence number\" on domain events?","text":"<p>While this is easy to support in some event stores like MSSQL, it doesn't really make sense from a domain perspective. Greg Young also has this to say on the subject:</p> <p>Quote</p> <p>Order is only assured per a handler within an aggregate root boundary. There is no assurance of order between handlers or between aggregates. Trying to provide those things leads to the dark side. &gt;</p> <p>Greg Young</p>"},{"location":"additional/faq/#why-doesnt-eventflow-have-a-unit-of-work-concept","title":"Why doesn't EventFlow have a unit of work concept?","text":"<p>Short answer, you shouldn't need it. But Mike has a way better answer:</p> <p>Quote</p> <p>In the Domain, everything flows in one direction: forward. When something bad happens, a correction is applied. The Domain doesn't care about the database and UoW is very coupled to the db. In my opinion, it's a pattern which is usable only with data access objects, and in probably 99% of the cases you won't be needing it. As with the Singleton, there are better ways but everything depends on proper domain design. &gt; `Mike</p> <p>Mogosanu</p> <p>If your case falls within the 1% case, write a decorator for the <code>ICommandBus</code> that starts a transaction, use MSSQL as event store and make sure your read models are stored in MSSQL as well.</p>"},{"location":"additional/faq/#why-are-subscribers-receiving-events-out-of-order","title":"Why are subscribers receiving events out of order?","text":"<p>It might be that your aggregates are emitting multiple events. Read about subscribers and out of order events.</p>"},{"location":"additional/snapshots/","title":"Snapshots","text":"<p>When working with long-lived aggregates, performance when loading aggregates, and thereby making changes to them, becomes a real concern. Consider aggregates that are comprised of several thousands of events, some of which need to go through a rigorous update process before they are applied to the aggregates.</p> <p>EventFlow supports aggregate snapshots, which is basically a capture of the entire aggregate state every few events. So instead of loading the entire aggregate event history, the latest snapshot is loaded, then applied to the aggregate and then the remaining events that were not captured in the snapshot.</p> <p>To configure an aggregate root to support snapshots, inherit from <code>SnapshotAggregateRoot&lt;,,&gt;</code> and define a serializable snapshot type that is marked with the <code>ISnapshot</code> interface.</p> <pre><code>[SnapshotVersion(\"user\", 1)]\npublic class UserSnapshot : ISnapshot\n{\n  // Add properties and methods to represent the snapshot state\n}\n\npublic class UserAggregate :\n  SnapshotAggregateRoot&lt;UserAggregate, UserId, UserSnapshot&gt;\n{\n  protected override Task&lt;UserSnapshot&gt; CreateSnapshotAsync(\n    CancellationToken cancellationToken)\n  {\n    // Create a UserSnapshot based on the current aggregate state\n    return Task.FromResult(new UserSnapshot\n    {\n      // Initialize snapshot properties with the current aggregate state\n    });\n  }\n\n  protected override Task LoadSnapshotAsync(\n    UserSnapshot snapshot,\n    ISnapshotMetadata metadata,\n    CancellationToken cancellationToken)\n  {\n    // Load the UserSnapshot into the current aggregate\n    // Update the aggregate state with the snapshot properties\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>When using aggregate snapshots, there are several important details to remember:</p> <ul> <li>Aggregates must not make any assumptions regarding the existence of   snapshots.</li> <li>Aggregates must not assume that snapshots are created with increasing   aggregate sequence numbers.</li> <li>Snapshots must be created in such a way that they represent the   entire history up to the point of snapshot creation.</li> </ul>"},{"location":"additional/snapshots/#snapshot-strategy","title":"Snapshot strategy","text":"<p>When implementing an aggregate root that inherits from <code>SnapshotAggregateRoot&lt;,,&gt;</code>, you need to pass the base class an implementation of <code>ISnapshotStrategy</code>. The strategy is used to determine when a snapshot should be created, e.g., every 100 events.</p> <p>EventFlow ships with two strategies that should be enough for most purposes as they can be configured:</p> <ul> <li><code>SnapshotEveryFewVersionsStrategy:</code> Snapshots are created after a   predefined number of events, the default is <code>100</code>, but another   frequency can be specified.</li> <li><code>SnapshotRandomlyStrategy:</code> Snapshots are created randomly with a   predefined chance, the default is <code>1%</code>, but another can be   specified.</li> </ul>"},{"location":"additional/snapshots/#upgrading-snapshots","title":"Upgrading snapshots","text":"<p>As an application grows over time, the data required to be stored within a snapshot will change. Either because some become obsolete or merely because a better way of storing the aggregate state is found. If this happens, the snapshots persisted in the snapshot store could potentially become useless as aggregates are unable to apply them. The easy solution would be to make change-by-addition and make sure that the old snapshots can be deserialized into the new version.</p> <p>EventFlow provides an alternative solution, which is basically allowing developers to upgrade snapshots similar to how events are upgraded.</p> <p>Let's say we have an application that has developed three snapshot versions over time.</p> <pre><code>[SnapshotVersion(\"user\", 1)]\npublic class UserSnapshotV1 : ISnapshot\n{\n  // Add properties and methods to represent the snapshot state for version 1\n}\n\n[SnapshotVersion(\"user\", 2)]\npublic class UserSnapshotV2 : ISnapshot\n{\n  // Add properties and methods to represent the snapshot state for version 2\n}\n\n[SnapshotVersion(\"user\", 3)]\npublic class UserSnapshot : ISnapshot\n{\n  // Add properties and methods to represent the snapshot state for version 3\n}\n</code></pre> <p>Note how version three of the <code>UserAggregate</code> snapshot is called <code>UserSnapshot</code> and not <code>UserSnapshotV3</code>, it's basically to help developers tell which snapshot version is the current one.</p> <p>Remember to add the <code>[SnapshotVersion]</code> attribute as it enables control of the snapshot definition name. If left out, EventFlow will make a guess, which will be tied to the name of the class type.</p> <p>The next step will be to implement upgraders, or mappers, that can upgrade one snapshot to another.</p> <pre><code>public class UserSnapshotV1ToV2Upgrader :\n  ISnapshotUpgrader&lt;UserSnapshotV1, UserSnapshotV2&gt;\n{\n  public Task&lt;UserSnapshotV2&gt; UpgradeAsync(\n    UserSnapshotV1 userSnapshotV1,\n    CancellationToken cancellationToken)\n  {\n    // Map from V1 to V2 and return\n    return Task.FromResult(new UserSnapshotV2\n    {\n      // Initialize properties with the mapped values from V1\n    });\n  }\n}\n\npublic class UserSnapshotV2ToV3Upgrader :\n  ISnapshotUpgrader&lt;UserSnapshotV2, UserSnapshot&gt;\n{\n  public Task&lt;UserSnapshot&gt; UpgradeAsync(\n    UserSnapshotV2 userSnapshotV2,\n    CancellationToken cancellationToken)\n  {\n    // Map from V2 to V3 and return\n    return Task.FromResult(new UserSnapshot\n    {\n      // Initialize properties with the mapped values from V2\n    });\n  }\n}\n</code></pre> <p>The snapshot types and upgraders then only need to be registered in EventFlow.</p> <pre><code>  // ...\n  .AddSnapshotUpgraders(myAssembly)\n  .AddSnapshots(myAssembly)\n  // ...\n</code></pre> <p>Now, whenever a snapshot is loaded from the snapshot store, it is automatically upgraded to the latest version and the aggregate only needs to concern itself with the latest version.</p>"},{"location":"additional/snapshots/#snapshot-store-implementations","title":"Snapshot store implementations","text":"<p>EventFlow has built-in support for some snapshot stores (more will be implemented).</p>"},{"location":"additional/snapshots/#null-or-none","title":"Null (or none)","text":"<p>The default implementation used by EventFlow does absolutely nothing besides logging a warning if used. It exists only to help developers to select a proper snapshot store. Making in-memory the default implementation could present problems if snapshots were configured, but the snapshot store configuration forgotten.</p>"},{"location":"additional/snapshots/#in-memory","title":"In-memory","text":"<p>For testing, or small applications, the in-memory snapshot store is configured by merely calling <code>UseInMemorySnapshotStore()</code>. <pre><code>  // ...\n  .UseInMemorySnapshotStore()\n  // ...\n</code></pre></p>"},{"location":"additional/snapshots/#microsoft-sql-server","title":"Microsoft SQL Server","text":"<p>To use the MSSQL snapshot store, you need to install the NuGet package <code>EventFlow.MsSql</code>.</p>"},{"location":"additional/snapshots/#configuration","title":"Configuration","text":"<p>Configure the MSSQL connection and snapshot store as shown here.</p> <pre><code>public void ConfigureServices(IServiceCollection services)\n{\n  services.AddEventFlow(ef =&gt;\n  {\n    ef.ConfigureMsSql(MsSqlConfiguration.New\n      .SetConnectionString(@\"Server=.\\SQLEXPRESS;Database=MyApp;User Id=sa;Password=???\"))\n    .UseMsSqlSnapshotStore();\n  });\n}\n</code></pre> <p>Note that if you already use MSSQL for the event- or read model store, you only need to invoke the <code>ConfigureMsSql</code> extension once.</p>"},{"location":"additional/snapshots/#create-and-migrate-required-mssql-databases","title":"Create and migrate required MSSQL databases","text":"<p>Before you can use the MSSQL snapshot store, the required database and tables must be created. The database specified in your MSSQL connection will not be automatically created, you have to do this yourself.</p> <p>To make EventFlow create the required tables, execute the following code.</p> <pre><code>var msSqlDatabaseMigrator = serviceProvider.GetRequiredService&lt;IMsSqlDatabaseMigrator&gt;();\nEventFlowSnapshotStoresMsSql.MigrateDatabase(msSqlDatabaseMigrator);\n</code></pre> <p>You should do this either on application start or preferably upon application install or update, e.g., when the website is installed.</p>"},{"location":"additional/snapshots/#custom","title":"Custom","text":"<p>If none of the above stores are adequate, a custom implementation is possible by implementing the interface <code>ISnapshotPersistence</code>. However, there are some rules that the snapshot persistence store must follow:</p> <ul> <li>It's valid to store snapshots in any order, e.g., first version 3 then 2.</li> <li>It's valid to overwrite existing snapshot versions, e.g., storing version 3 then version 3 again.</li> <li>Fallback to old snapshots is allowed.</li> </ul>"},{"location":"additional/specifications/","title":"Specifications","text":"<p>EventFlow ships with an implementation of the  specification pattern which could be used to e.g. make complex business rules easier to read and test.</p> <p>To use the specification implementation shipped with EventFlow, simply create a class that inherits from <code>Specification&lt;T&gt;</code>.</p> <pre><code>public class BelowFiveSpecification : Specification&lt;int&gt;\n{\n  protected override IEnumerable&lt;string&gt; IsNotSatisfiedBecause(int i)\n  {\n    if (5 &lt;= i)\n    {\n        yield return string.Format(\"{0} is not below five\", i);\n    }\n  }\n}\n</code></pre> <p>Note that instead of simply returning a <code>bool</code> to indicate whether or not the specification is satisfied, this implementation requires a reason (or reasons) why the specification is not satisfied.</p> <p>The <code>ISpecification&lt;T&gt;</code> interface has two methods defined, the traditional <code>IsSatisfiedBy</code> as well as <code>WhyIsNotSatisfiedBy</code>, which returns an empty enumerable if the specification was indeed satisfied.</p> <pre><code>public interface ISpecification&lt;in T&gt;\n{\n  bool IsSatisfiedBy(T obj);\n\n  IEnumerable&lt;string&gt; WhyIsNotSatisfiedBy(T obj);\n}\n</code></pre> <p>Specifications really become powerful when they are combined. EventFlow also ships with a series of extension methods for the <code>ISpecification&lt;T&gt;</code> interface that allows easy combination of implemented specifications.</p> <pre><code>// Throws a `DomainError` exception if obj doesn't satisfy the specification\nspec.ThrowDomainErrorIfNotStatisfied(obj);\n\n// Builds a new specification that requires all input specifications to be\n// satified\nvar allSpec = specEnumerable.All();\n\n// Builds a new specification that requires a predefined amount of the\n// input specifications to be satisfied\nvar atLeastSpec = specEnumerable.AtLeast(4);\n\n// Builds a new specification that requires the two input specifications\n// to be satisfied\nvar andSpec = spec1.And(spec2);\n\n// Builds a new specification that requires one of the two input\n// specifications to be satisfied\nvar orSpec = spec1.Or(spec2);\n\n// Builds a new specification that requires the input specification\n// not to be satisfied\nvar notSpec = spec.Not();\n</code></pre> <p>If you need a simple expression to combine with other more complex specifications you can use the bundled <code>ExpressionSpecification&lt;T&gt;</code>, which is a specification wrapper for an expression.</p> <pre><code>var spec = new ExpressionSpecification&lt;int&gt;(i =&gt; 1 &lt; i &amp;&amp; i &lt; 3);\n\n// 'str' will contain the value \"i =&gt; ((1 &lt; i) &amp;&amp; (i &lt; 3))\"\nvar str = spec.ToString();\n</code></pre> <p>If the specification isn't satisfied, a string representation of the expression is returned.</p>"},{"location":"additional/value-objects/","title":"Event serialization and value objects","text":"<p>One of the important parts of creating an event sourced application is to ensure that you can always read your event streams. It seems simple enough, but it is a problem, especially for large applications that undergo refactoring or domain changes.</p> <p>The basic idea is to store events in a structure that's easy to access and migrate if the need should arise. EventFlow, like many other event sourced systems, stores its events using JSON.</p>"},{"location":"additional/value-objects/#making-pretty-and-clean-json","title":"Making pretty and clean JSON","text":"<p>You might wonder \"but, why?\", and the reason is somewhat similar to the reasoning behind semantic URLs.</p> <p>Consider the following value object used to validate and contain usernames in an application.</p> <pre><code>public class Username\n{\n  public string Value { get; }\n\n  public Username(string value)\n  {\n    if (string.IsNullOrEmpty(value) || value.Length &lt;= 4)\n    {\n      throw DomainError.With($\"Invalid username '{value}'\");\n    }\n\n    Value = value;\n  }\n}\n</code></pre> <p>First we do some cleanup and re-write it using EventFlows <code>SingleValueObject&lt;&gt;</code>.</p> <pre><code>public class Username : SingleValueObject&lt;string&gt;\n{\n  public Username(string value) : base(value)\n  {\n    if (string.IsNullOrEmpty(value) || value.Length &lt;= 4)\n    {\n      throw DomainError.With($\"Invalid username '{value}'\");\n    }\n  }\n}\n</code></pre> <p>Now it looks simple and we might think we can use this value object directly in our domain events. We could, but the resulting JSON will look like this.</p> <pre><code>{\n  \"Username\" : {\n    \"Value\": \"my-awesome-username\",\n  }\n}\n</code></pre> <p>This doesn't look very good. First, that extra property doesn't make it easier to read and it takes up more space when serializing and transmitting the event.</p> <p>In addition, if you use the value object in a web API, people using the API will need to wrap the properties in their DTOs in a similar way. What we would like is to modify our serialized event to look like this instead and still use the value object in our events.</p> <pre><code>{\n  \"Username\" : \"my-awesome-username\"\n}\n</code></pre> <p>To do this, we use the custom JSON serializer EventFlow has for single value objects called <code>SingleValueObjectConverter</code> on our <code>Username</code> class like this.</p> <pre><code>[JsonConverter(typeof(SingleValueObjectConverter))] // Only this line added\npublic class Username : SingleValueObject&lt;string&gt;\n{\n  public Username(string value) : base(value)\n  {\n    if (string.IsNullOrEmpty(value) || value.Length &lt;= 4)\n    {\n      throw DomainError.With($\"Invalid username '{value}'\");\n    }\n  }\n}\n</code></pre> <p>The JSON converter understands the single value object and will serialize and deserialize it correctly.</p> <p>Using this converter also enables to you replace e.g. raw <code>string</code> and <code>int</code> properties with value objects on existing events as they will be \"JSON compatible\".</p> <p>Note</p> <p>Consider applying this to any classes that inherit from <code>Identity&lt;&gt;</code>.</p>"},{"location":"basics/aggregates/","title":"Aggregates","text":"<p>Before you can create an aggregate, you need to create its identity. You can create your own implementation by implementing the <code>IIdentity</code> interface or you can use the base class <code>Identity&lt;&gt;</code> that EventFlow provides, like this:</p> <pre><code>public class TestId : Identity&lt;TestId&gt;\n{\n  public TestId(string value) : base(value)\n  {\n  }\n}\n</code></pre> <p>The <code>Identity&lt;&gt;</code> value object provides generic functionality to create and validate aggregate root IDs. Please read the documentation regarding the bundled <code>Identity&lt;&gt;</code> type as it provides several useful features, such as different schemes for ID generation, including one that minimizes MSSQL database fragmentation.</p> <p>Next, to create a new aggregate, simply inherit from <code>AggregateRoot&lt;,&gt;</code> like this, making sure to pass the aggregate's own type as the first generic argument and the identity as the second:</p> <pre><code>public class TestAggregate : AggregateRoot&lt;TestAggregate, TestId&gt;\n{\n  public TestAggregate(TestId id)\n    : base(id)\n  {\n  }\n}\n</code></pre>"},{"location":"basics/aggregates/#events","title":"Events","text":"<p>In an event-sourced system like EventFlow, aggregate root data is stored on events.</p> <pre><code>public class PingEvent : AggregateEvent&lt;TestAggregate, TestId&gt;\n{\n  public string Data { get; }\n\n  public PingEvent(string data)\n  {\n      Data = data;\n  }\n}\n</code></pre> <p>Please make sure to read the section on value objects and events for some important notes on creating events.</p>"},{"location":"basics/aggregates/#emitting-events","title":"Emitting events","text":"<p>In order to emit an event from an aggregate, call the <code>protected</code> <code>Emit(...)</code> method, which applies the event and adds it to the list of uncommitted events.</p> <pre><code>public void Ping(string data)\n{\n  // Fancy domain logic here that validates aggregate state...\n\n  if (string.IsNullOrEmpty(data))\n  {\n    throw DomainError.With(\"Ping data is empty\");\n  }\n\n  Emit(new PingEvent(data));\n}\n</code></pre> <p>Remember not to make any changes to the aggregate with these methods, as the state is only stored through events.</p>"},{"location":"basics/aggregates/#applying-events","title":"Applying events","text":"<p>Currently, EventFlow has four methods of applying events to the aggregate when emitted or loaded from the event store. Which you choose is up to you. Implementing <code>IEmit&lt;SomeEvent&gt;</code> is the most convenient, but will expose public <code>Apply</code> methods.</p> <ul> <li>Create a method called <code>Apply</code> that takes the event as an argument. To get the method signature right, implement the <code>IEmit&lt;SomeEvent&gt;</code> on your aggregate. This is the default fallback, and you will get an exception if no other strategies are configured. Although you can implement <code>IEmit&lt;SomeEvent&gt;</code>, it's optional. The <code>Apply</code> methods can be <code>protected</code> or <code>private</code>.</li> <li>Create a state object by inheriting from <code>AggregateState&lt;,,&gt;</code> and registering it using the protected <code>Register(...)</code> in the aggregate root constructor.</li> <li>Register a specific handler for an event using the protected <code>Register&lt;SomeEvent&gt;(e =&gt; Handler(e))</code> from within the constructor.</li> <li>Register an event applier using <code>Register(IEventApplier eventApplier)</code>, which could be, for example, a state object.</li> </ul>"},{"location":"basics/commands/","title":"Commands","text":"<p>Commands are the basic value objects, or models, that represent the  write operations that you can perform in your domain. As described  in more detail below a command is the \"thing\" to be done.  A command  handler does the \"thing\".</p> <p>As an example, one might implement this command for updating user passwords.  </p> <pre><code>public class UserUpdatePasswordCommand : Command&lt;UserAggregate, UserId&gt;\n{\n  public Password NewPassword { get; }\n  public Password OldPassword { get; }\n\n  public UserUpdatePasswordCommand(\n    UserId id,\n    Password newPassword,\n    Password oldPassword)\n    : base(id)\n  {\n    NewPassword = newPassword;\n    OldPassword = oldPassword;\n  }\n}\n</code></pre> <p>Note that the <code>Password</code> class is merely a value object created to hold the password and do basic validation. Read the article regarding value objects for more information. Also, you don't have to use the default EventFlow <code>Command&lt;,&gt;</code> implementation, you can create your own, it merely has to implement the <code>ICommand&lt;,&gt;</code> interface.</p> <p>A command by itself doesn't do anything and will throw an exception if published. To make a command work, you need to implement one (and only one) command handler which is responsible for invoking the aggregate.</p> <pre><code>public class UserUpdatePasswordCommandHandler : CommandHandler&lt;UserAggregate, UserId, UserUpdatePasswordCommand&gt;\n{\n  public override Task ExecuteAsync(\n    UserAggregate aggregate,\n    UserUpdatePasswordCommand command,\n    CancellationToken cancellationToken)\n  {\n    return aggregate.UpdatePasswordAsync(\n      command.NewPassword,\n      command.OldPassword,\n      cancellationToken);\n  }\n}\n</code></pre>"},{"location":"basics/commands/#execution-results","title":"Execution results","text":"<p>If the aggregate detects a domain error and wants to abort execution  and return an error back, then execution results are used. EventFlow ships with a basic implementation that allows returning success or  failed and optionally an error message as shown here.</p> <pre><code>ExecutionResult.Success();\nExecutionResult.Failed();\nExecutionResult.Failed(\"With some error\");\n</code></pre> <p>However, you can create your own custom execution results to allow aggregates to e.g. provide detailed validation results. Merely implement the <code>IExecutionResult</code> interface and use the type as generic arguments on the command and command handler.</p> <p>Tip</p> <p>While possible, do not use the execution results as a method of reading values from the aggregate, that's what the <code>IQueryProcessor</code> and read models are for.</p>"},{"location":"basics/commands/#ensure-idempotency","title":"Ensure idempotency","text":"<p>Detecting duplicate operations can be hard, especially if you have a distributed application, or simply a web application. Consider the following simplified scenario.</p> <ol> <li>The user wants to change his password</li> <li>The user fills in the \"change password form\"</li> <li>The user submits the form twice, either accidentally or impatiently</li> <li>The first web request completes and the password is changed. However,    as the browser is waiting on the second web request, this result is    ignored</li> <li>The second web request throws a domain error as the \"old password\"    doesn't match as the current password has already been changed</li> <li>The user is presented with a error on the web page</li> </ol> <p>Handling this is simple, merely ensure that the aggregate is idempotent in regards to password changes. But instead of implementing this yourself, EventFlow has support for it that is simple to utilize and is done per command.</p> <p>To use the functionality, merely ensure that commands that represent the same operation have the same <code>ISourceId</code> which implements <code>IIdentity</code> like the example below.</p> <pre><code>public class UserUpdatePasswordCommand : Command&lt;UserAggregate, UserId&gt;\n{\n  public Password NewPassword { get; }\n  public Password OldPassword { get; }\n\n  public UserCreateCommand(\n    UserId id,\n    ISourceId sourceId,\n    Password newPassword,\n    Password oldPassword)\n    : base(id, sourceId)\n  {\n    NewPassword = newPassword;\n    OldPassword = oldPassword;\n  }\n}\n</code></pre> <p>Note the use on line 11 of the  <code>protected</code> constructor of <code>Command&lt;,&gt;</code> that takes a <code>ISourceId</code> in addition to the aggregate root identity.</p> <p>If a duplicate command is detected, a <code>DuplicateOperationException</code> is thrown. The application could then ignore the exception or report the problem to the end user.</p> <p>The default <code>ISourceId</code> history size of the aggregate root, is ten. But it can be configured using the <code>SetSourceIdHistory(...)</code> method  in the aggregate root constructor.</p>"},{"location":"basics/commands/#easier-isourceid-calculation","title":"Easier <code>ISourceId</code> calculation","text":"<p>Ensuring the correct calculation of the command <code>ISourceId</code> can be somewhat cumbersome, which is why EventFlow provides another base command you can use, the <code>DistinctCommand&lt;,&gt;</code>. By using the <code>DistinctCommand&lt;,&gt;</code> you merely have to implement the <code>GetSourceIdComponents()</code> and providing the <code>IEnumerable&lt;byte[]&gt;</code> that makes the command unique. The bytes are used to create a deterministic GUID to be used as an <code>ISourceId</code>.</p> <pre><code>public class UserUpdatePasswordCommand :\n  DistinctCommand&lt;UserAggregate, UserId&gt;\n{\n  public Password NewPassword { get; }\n  public Password OldPassword { get; }\n\n  public UserUpdatePasswordCommand(\n    UserId id,\n    Password newPassword,\n    Password oldPassword)\n    : base(id)\n  {\n    NewPassword = newPassword;\n    OldPassword = oldPassword;\n  }\n\n  protected override IEnumerable&lt;byte[]&gt; GetSourceIdComponents()\n  {\n    yield return NewPassword.GetBytes();\n    yield return OldPassword.GetBytes();\n  }\n}\n</code></pre> <p>The <code>GetBytes()</code> merely returns the <code>Encoding.UTF8.GetBytes(...)</code> of the password.</p> <p>Danger</p> <p>Don't use the <code>GetHashCode()</code>, as the implementation can be different on 32 bit and 64 bit .NET (e.g. <code>string</code>) and can change between .NET versions.</p>"},{"location":"basics/event-upgrade/","title":"Event upgrade","text":"<p>At some point, you might find the need to replace an event with zero or more events. Some use cases might be:</p> <ul> <li>A previous application version introduced a domain error in the form of a wrong event being emitted from the aggregate.</li> <li>The domain has changed, either from a change in requirements or simply from a better understanding of the domain.</li> </ul> <p>EventFlow event upgraders are invoked whenever the event stream is loaded from the event store. Each event upgrader receives the entire event stream one event at a time.</p> <p>A new instance of an event upgrader is created each time an aggregate is loaded. This enables you to store information from previous events on the upgrader instance to be used later, e.g., to determine an action to take on an event or to provide additional information for a new event.</p> <p>Note that the ordering of event upgraders is important as you might implement two upgraders, one to upgrade an event from V1 to V2 and then another upgrading V2 to V3. EventFlow orders the event upgraders by name before starting the event upgrade.</p> <p>Warning</p> <p>Be careful when working with event upgraders that return zero or more than one event, as this has an influence on the aggregate version and you need to make sure that the aggregate sequence number on upgraded events is valid in regard to the aggregate history.</p>"},{"location":"basics/event-upgrade/#example-removing-a-damaged-event","title":"Example - removing a damaged event","text":"<p>To remove an event, simply check and only return the event if it's not the event you want to remove.</p> <pre><code>public class DamagedEventRemover : IEventUpgrader&lt;MyAggregate, MyId&gt;\n{\n  public IEnumerable&lt;IDomainEvent&lt;TestAggregate, TestId&gt;&gt; Upgrade(\n    IDomainEvent&lt;TestAggregate, TestId&gt; domainEvent)\n  {\n    var damagedEvent = domainEvent as IDomainEvent&lt;MyAggregate, MyId, DamagedEvent&gt;;\n    if (damagedEvent == null)\n    {\n      yield return domainEvent;\n    }\n  }\n}\n</code></pre>"},{"location":"basics/event-upgrade/#example-replace-event","title":"Example - replace event","text":"<p>To upgrade one event to another, you should use the <code>IDomainEventFactory.Upgrade</code> to help migrate metadata and create the new event.</p> <pre><code>public class UpgradeMyEventV1ToMyEventV2 : IEventUpgrader&lt;MyAggregate, MyId&gt;\n{\n  private readonly IDomainEventFactory _domainEventFactory;\n\n  public UpgradeTestEventV1ToTestEventV2(IDomainEventFactory domainEventFactory)\n  {\n    _domainEventFactory = domainEventFactory;\n  }\n\n  public IEnumerable&lt;IDomainEvent&lt;TestAggregate, TestId&gt;&gt; Upgrade(\n    IDomainEvent&lt;TestAggregate, TestId&gt; domainEvent)\n  {\n    var myEventV1 = domainEvent as IDomainEvent&lt;MyAggregate, MyId, MyEventV1&gt;;\n    yield return myEventV1 == null\n      ? domainEvent\n      : _domainEventFactory.Upgrade&lt;MyAggregate, MyId&gt;(\n        domainEvent, new MyEventV2());\n  }\n}\n</code></pre>"},{"location":"basics/identity/","title":"Identity","text":"<p>The <code>Identity&lt;&gt;</code> value object provides generic functionality to create and validate the IDs of aggregate roots. It is basically a wrapper around a <code>Guid</code>.</p> <p>Let's say we want to create a new identity named <code>TestId</code>. We could do it like this:</p> <pre><code>public class TestId : Identity&lt;TestId&gt;\n{\n  public TestId(string value)\n    : base(value)\n  {\n  }\n}\n</code></pre> <ul> <li>The identity follows the form <code>{classname without \"Id\"}-{guid}</code> e.g.    <code>test-c93fdb8c-5c9a-4134-bbcd-87c0644ca34f</code> for the above    <code>TestId</code> example.</li> <li> <p>The internal <code>Guid</code> can be generated using one of the following    methods/properties. Note that you can access the <code>Guid</code> factories    directly by accessing the static methods on the <code>GuidFactories</code>    class:</p> <ul> <li><code>New</code>: Uses the standard <code>Guid.NewGuid()</code>.</li> <li><code>NewDeterministic(...)</code>: Creates a name-based <code>Guid</code> using the      algorithm from RFC 4122      \u00a74.3, which allows identities to be generated based on known data,      (e.g., a user e-mail). It always returns the same identity for      the same arguments.</li> <li><code>NewComb()</code>: Creates a sequential <code>Guid</code> that can be used to      avoid database fragmentation.</li> </ul> </li> <li> <p>A <code>string</code> can be tested to see if it's a valid identity using the    static <code>bool IsValid(string)</code> method.</p> </li> <li>Any validation errors can be gathered using the static    <code>IEnumerable&lt;string&gt; Validate(string)</code> method.</li> </ul> <p>Attention</p> <p>It's very important to name the constructor argument <code>value</code> as it is significant when the identity type is deserialized.</p> <p>Here are some examples of how we can use our newly created <code>TestId</code>:</p> <pre><code>// Uses the default Guid.NewGuid()\nvar testId = TestId.New;\n</code></pre> <pre><code>// Create a namespace, put this in a constant somewhere\nvar emailNamespace = Guid.Parse(\"769077C6-F84D-46E3-AD2E-828A576AAAF3\");\n\n// Creates an identity with the value \"test-9181a444-af25-567e-a866-c263b6f6119a\"\nvar testId = TestId.NewDeterministic(emailNamespace, \"test@example.com\");\n</code></pre> <pre><code>// Creates a new identity every time, but an identity when used in\n// database indexes, minimizes fragmentation\nvar testId = TestId.NewComb();\n</code></pre> <p>Tip</p> <p>Be sure to read the section about value objects as the <code>Identity&lt;&gt;</code> is basically a value object.</p>"},{"location":"basics/jobs/","title":"Jobs","text":"<p>A job is basically a task that you want to execute outside of the current context, on another server or at a later time. EventFlow provides basic functionality for jobs.</p> <p>There are areas where you might find jobs very useful, here are some examples</p> <ul> <li>Publish a command at a specific time in the future</li> <li>Transient error handling</li> </ul> <pre><code>var jobScheduler = resolver.Resolve&lt;IJobScheduler&gt;();\nvar job = PublishCommandJob.Create(new SendEmailCommand(id), resolver);\nawait jobScheduler.ScheduleAsync(\n  job,\n  TimeSpan.FromDays(7),\n  CancellationToken.None)\n  .ConfigureAwait(false);\n</code></pre> <p>In the above example the <code>SendEmailCommand</code> command will be published in seven days.</p> <p>Attention</p> <p>When working with jobs, you should be aware of the following</p> <ul> <li>The default implementation does executes the job now (completely ignoring <code>runAt</code>/<code>delay</code> parameters) and in the   current context. To get support for scheduled jobs, inject another implementation of <code>IJobScheduler</code>,   e.g. by  installing <code>EventFlow.Hangfire</code> (Read below for details).</li> <li>Your jobs should serialize to JSON properly, see the section on   value objects for more information</li> <li>If you use the provided <code>PublishCommandJob</code>, make sure that your   commands serialize properly as well</li> </ul>"},{"location":"basics/jobs/#create-your-own-jobs","title":"Create your own jobs","text":"<p>To create your own jobs, your job merely needs to implement the <code>IJob</code> interface and be registered in EventFlow.</p> <p>Here's an example of a job implementing <code>IJob</code></p> <pre><code>[JobVersion(\"LogMessage\", 1)]\npublic class LogMessageJob : IJob\n{\n  public LogMessageJob(string message)\n  {\n    Message = message;\n  }\n\n  public string Message { get; }\n\n  public Task ExecuteAsync(\n    IServiceProvider serviceProvider,\n    CancellationToken cancellationToken)\n  {\n    var log = serviceProvider.GetRequiredService&lt;ILogger&lt;LogMessageJob&gt;&gt;();\n    log.LogDebug(Message);\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>Note that the <code>JobVersion</code> attribute specifies the job name and version to EventFlow and this is how EventFlow distinguishes between the different job types. This makes it possible for you to reorder your code, even rename the job type. As long as you keep the same attribute values it is considered the same job in EventFlow. If the attribute is omitted, the name will be the type name and version will be <code>1</code>.</p> <p>Here's how the job is registered in EventFlow.</p> <pre><code>public void ConfigureServices(IServiceCollection services)\n{\n  services.AddEventFlow(ef =&gt;\n  {\n    ef.AddJobs(typeof(LogMessageJob));\n  });\n}\n</code></pre> <p>Then to schedule the job</p> <pre><code>var jobScheduler = serviceProvider.GetRequiredService&lt;IJobScheduler&gt;();\nvar job = new LogMessageJob(\"Great log message\");\nawait jobScheduler.ScheduleAsync(\n  job,\n  TimeSpan.FromDays(7),\n  CancellationToken.None)\n  .ConfigureAwait(false);\n</code></pre>"},{"location":"basics/jobs/#hangfire","title":"Hangfire","text":"<p>To use Hangfire as the job scheduler, install the NuGet package <code>EventFlow.Hangfire</code> and configure EventFlow to use the scheduler like this.</p> <p>hangfire supports several different storage solutions including Microsoft SQL Server and MongoDB. Use only inMemoryStorage for testing and development.</p> <pre><code>private void RegisterHangfire(IEventFlowOptions eventFlowOptions)\n{\n    eventFlowOptions.ServiceCollection\n        .AddHangfire(c =&gt; c.UseInMemoryStorage())\n        .AddHangfireServer();\n    eventFlowOptions.UseHangfireJobScheduler();\n}\n</code></pre> <p>Note</p> <p>The <code>UseHangfireJobScheduler()</code> doesn't do any Hangfire configuration, but merely registers the proper scheduler in EventFlow.</p>"},{"location":"basics/metadata/","title":"Metadata","text":"<p>Metadata is all the \"additional\" information that resides with an emitted event, some of which is required information.</p> <p>In EventFlow, metadata is merely an <code>IEnumerable</code> of <code>KeyValuePair&lt;string,string&gt;</code> for which each is a metadata entry.</p> <p>Out of the box, these metadata keys are added to each aggregate event:</p> <ul> <li><code>event_name</code> and <code>event_version</code> - A name and version for the    event which is used during event deserialization.</li> <li><code>timestamp</code> - A <code>DateTimeOffset</code> for when the event was emitted    from the aggregate.</li> <li><code>aggregate_sequence_number</code> - The version the aggregate was after    the event was emitted, e.g., <code>1</code> for the very first event emitted.</li> </ul>"},{"location":"basics/metadata/#custom-metadata-provider","title":"Custom metadata provider","text":"<p>If you require additional information to be stored along with each event, you can implement the <code>IMetadataProvider</code> interface and register the class using e.g., <code>.AddMetadataProvider(...)</code> on <code>EventFlowOptions</code>.</p>"},{"location":"basics/metadata/#additional-built-in-providers","title":"Additional built-in providers","text":"<p>EventFlow ships with a collection of ready-to-use providers in some of its NuGet packages.</p>"},{"location":"basics/metadata/#eventflow","title":"EventFlow","text":"<ul> <li> <p><code>AddEventTypeMetadataProvider</code></p> <ul> <li><code>event_type_assembly_name</code> - Assembly name of the assembly containing the event.</li> <li><code>event_type_assembly_version</code> - Assembly version of the assembly containing the event.</li> <li><code>event_type_fullname</code> - Full name of the event corresponding to <code>Type.FullName</code> for the aggregate event type.</li> </ul> </li> <li> <p><code>AddGuidMetadataProvider</code></p> <ul> <li><code>guid</code> - A new <code>Guid</code> for each event.</li> </ul> </li> <li> <p><code>AddMachineNameMetadataProvider</code></p> <ul> <li><code>environment_machinename</code> - Adds the machine name handling the event from <code>Environment.MachineName</code>.</li> </ul> </li> </ul>"},{"location":"basics/queries/","title":"Queries","text":"<p>Creating queries in EventFlow is simple.</p> <p>First, create a value object that contains the data required for the query. In this example, we want to search for users based on their username.</p> <pre><code>public class GetUserByUsernameQuery : IQuery&lt;User&gt;\n{\n  public string Username { get; }\n\n  public GetUserByUsernameQuery(string username)\n  {\n    Username = username;\n  }\n}\n</code></pre> <p>Next, create a query handler that implements how the query is processed.</p> <pre><code>public class GetUserByUsernameQueryHandler :\n  IQueryHandler&lt;GetUserByUsernameQuery, User&gt;\n{\n  private readonly IUserReadModelRepository _userReadModelRepository;\n\n  public GetUserByUsernameQueryHandler(\n    IUserReadModelRepository userReadModelRepository)\n  {\n    _userReadModelRepository = userReadModelRepository;\n  }\n\n  public Task&lt;User&gt; ExecuteQueryAsync(\n    GetUserByUsernameQuery query,\n    CancellationToken cancellationToken)\n  {\n    return _userReadModelRepository.GetByUsernameAsync(\n      query.Username,\n      cancellationToken);\n  }\n}\n</code></pre> <p>The last step is to register the query handler in EventFlow. Here we show the simple, but cumbersome version. You should use one of the overloads that scans an entire assembly.</p> <pre><code>//...\n.AddQueryHandler&lt;GetUserByUsernameQueryHandler, GetUserByUsernameQuery, User&gt;();\n//...\n</code></pre> <p>Then, to use the query in your application, you need a reference to the <code>IQueryProcessor</code>, which in our case is stored in the <code>_queryProcessor</code> field.</p> <pre><code>var user = await _queryProcessor.ProcessAsync(\n  new GetUserByUsernameQuery(\"root\"),\n  cancellationToken);\n</code></pre>"},{"location":"basics/queries/#queries-shipped-with-eventflow","title":"Queries shipped with EventFlow","text":"<ul> <li><code>ReadModelByIdQuery&lt;TReadModel&gt;</code>: Supported by both the in-memory    and MSSQL read model stores automatically as soon as you define the    read model use using the EventFlow options for that store.</li> <li><code>InMemoryQuery&lt;TReadModel&gt;</code>: Takes a <code>Predicate&lt;TReadModel&gt;</code> and    returns <code>IEnumerable&lt;TReadModel&gt;</code>, making it possible to search all    of your in-memory read models based on any predicate.</li> </ul>"},{"location":"basics/sagas/","title":"Sagas","text":"<p>EventFlow provides a simple saga system to coordinate messages between  bounded contexts and aggregates.</p> <ul> <li>Saga identity</li> <li>Saga</li> <li>Saga locator</li> <li>Zero or more aggregates</li> </ul> <p>This example is based on the chapter \"A Saga on Sagas\" from the CQRS Journey by Microsoft, in which we want to model the process of placing an order.</p> <ol> <li>User sends command <code>PlaceOrder</code> to the <code>OrderAggregate</code></li> <li><code>OrderAggregate</code> emits an <code>OrderCreated</code> event</li> <li><code>OrderSaga</code> handles <code>OrderCreated</code> by sending a    <code>MakeReservation</code> command to the <code>ReservationAggregate</code></li> <li><code>ReservationAggregate</code> emits a <code>SeatsReserved</code> event</li> <li><code>OrderSaga</code> handles <code>SeatsReserved</code> by sending a <code>MakePayment</code>    command to the <code>PaymentAggregate</code></li> <li><code>PaymentAggregate</code> emits a <code>PaymentAccepted</code> event</li> <li><code>OrderSaga</code> handles <code>PaymentAccepted</code> by emitting a    <code>OrderConfirmed</code> event with all the details, which via subscribers    updates the user, the <code>OrderAggregate</code> and the    <code>ReservationAggregate</code></li> </ol> <p>Next, we need an <code>ISagaLocator</code> which basically maps domain events to a saga identity allowing EventFlow to find it in its store.</p> <p>In our case, we will add the order ID to the event metadata of all events related to a specific order.</p> <pre><code>public class OrderSagaLocator : ISagaLocator\n{\n  public Task&lt;ISagaId&gt; LocateSagaAsync(\n    IDomainEvent domainEvent,\n    CancellationToken cancellationToken)\n  {\n    var orderId = domainEvent.Metadata[\"order-id\"];\n    var orderSagaId = new OrderSagaId($\"ordersaga-{orderId}\");\n\n    return Task.FromResult&lt;ISagaId&gt;(orderSagaId);\n  }\n}\n</code></pre> <p>Alternatively, the order identity could be added to every domain event emitted from the <code>OrderAggregate</code>, <code>ReservationAggregate</code>, and <code>PaymentAggregate</code> aggregates that the <code>OrderSaga</code> subscribes to, but this would depend on whether or not the order identity is part of the ubiquitous language for your domain.</p> <pre><code>public class OrderSaga\n  : AggregateSaga&lt;OrderSaga, OrderSagaId, OrderSagaLocator&gt;,\n    ISagaIsStartedBy&lt;OrderAggregate, OrderId, OrderCreated&gt;\n{\n  public Task HandleAsync(\n      IDomainEvent&lt;OrderAggregate, OrderId, OrderCreated&gt; domainEvent,\n      ISagaContext sagaContext,\n      CancellationToken cancellationToken)\n  {\n    // Update saga state with useful details.\n    Emit(new OrderStarted(/*...*/));\n\n    // Make the reservation\n    Publish(new MakeReservation(/*...*/));\n\n    return Task.FromResult(0);\n  }\n\n  public void Apply(OrderStarted e)\n  {\n    // Update our aggregate state with relevant order details\n  }\n}\n</code></pre> <p>Attention</p> <p>Even though the method for publishing commands is named <code>Publish</code>, the commands are only published to the command bus after the aggregate has been successfully committed to the event store (just like events). If an unexpected exception is thrown by this command publish, it should be handled by a custom implementation of <code>ISagaErrorHandler</code>.</p> <p>The next few events and commands are omitted in this example, but at last the <code>PaymentAggregate</code> emits its <code>PaymentAccepted</code> event and the saga completes and emits the final <code>OrderConfirmed</code> event.</p> <pre><code>public class OrderSaga\n  : AggregateSaga&lt;OrderSaga, OrderSagaId, OrderSagaLocator&gt;,\n    // ...\n    ISagaHandles&lt;PaymentAggregate, PaymentId, PaymentAccepted&gt;\n{\n  // ...\n\n  public Task HandleAsync(\n    IDomainEvent&lt;PaymentAggregate, PaymentId, PaymentAccepted&gt; domainEvent,\n    ISagaContext sagaContext,\n    CancellationToken cancellationToken)\n  {\n    Emit(new OrderConfirmed(/*...*/))\n  }\n\n  public void Apply(OrderConfirmed e)\n  {\n    // As this is the last event, we complete the saga by calling Complete()\n    Complete();\n  }\n}\n</code></pre> <p>Note</p> <p>An <code>AggregateSaga&lt;,,&gt;</code> is only considered in its <code>running</code> state if there has been an event and it hasn't been marked as completed (by invoking the <code>protected</code> <code>Complete()</code> method on the <code>AggregateSaga&lt;,,&gt;</code>).</p>"},{"location":"basics/sagas/#alternative-saga-store","title":"Alternative saga store","text":"<p>By default, EventFlow is configured to use event sourcing and aggregate roots for the storage of sagas. However, you can implement your own storage system by implementing <code>ISagaStore</code> and registering it.</p>"},{"location":"basics/subscribers/","title":"Subscribers","text":"<p>Whenever your application needs to perform an action when a specific  event is emitted from your domain, you create a class that implements one of the following two interfaces:</p> <ul> <li><code>ISubscribeSynchronousTo&lt;TAggregate,TIdentity,TEvent&gt;</code>: Executed    synchronously</li> <li><code>ISubscribeAsynchronousTo&lt;TAggregate,TIdentity,TEvent&gt;</code>: Executed    asynchronously</li> </ul> <p>Any subscribers that you implement need to be registered to this interface using either <code>AddSubscriber(...)</code>, <code>AddSubscribers(...)</code> or <code>AddDefaults(...)</code> during initialization. If you have configured a custom IoC container, you can register the implementations using it instead.</p> <p>Warning</p> <p>The synchronous and asynchronous here has nothing to do with the .NET framework keywords <code>async</code>, <code>await</code> or the Task Parallel Library. It refers to how the subscribers are executed. Read below for details.</p>"},{"location":"basics/subscribers/#synchronous-subscribers","title":"Synchronous subscribers","text":"<p>Synchronous subscribers in EventFlow are executed one at a time for each emitted domain event in order. This e.g. guarantees that all subscribers have been executed when the <code>ICommandBus.PublishAsync(...)</code> returns.</p> <p>The <code>ISubscribeSynchronousTo&lt;,,&gt;</code> interface is shown here.</p> <pre><code>public interface ISubscribeSynchronousTo&lt;TAggregate, in TIdentity, in TEvent&gt;\n  where TAggregate : IAggregateRoot&lt;TIdentity&gt;\n  where TIdentity : IIdentity\n  where TEvent : IAggregateEvent&lt;TAggregate, TIdentity&gt;\n{\n  Task HandleAsync(\n  IDomainEvent&lt;TAggregate, TIdentity, TEvent&gt; domainEvent,\n  CancellationToken cancellationToken);\n}\n</code></pre>"},{"location":"basics/subscribers/#out-of-order-events","title":"Out of order events","text":"<p>As synchronous subscribers are by their very nature executed synchronously, emitting multiple events from an aggregate and letting subscribers publish new commands based on this can lead to some unexpected behavior as \"innermost\" subscribers will be executed before the next \"outer\" event is handled by the subscriber.</p> <ol> <li>Aggregate emits events <code>Event 1</code> and <code>Event 2</code></li> <li>Subscriber handles <code>Event 1</code> and publishes a command that results    in <code>Event 3</code> being emitted</li> <li>Subscriber handles <code>Event 3</code> (doesn't affect the domain)</li> <li>Subscriber handles <code>Event 2</code></li> </ol> <p>In the above example the subscriber will handle the events in the following order <code>Event 1</code>, <code>Event 3</code> and then <code>Event 2</code>. While this could occur in a distributed system or when executing subscribers on different threads, it is a certainty when using synchronous subscribers.</p>"},{"location":"basics/subscribers/#exceptions-swallowed-by-default","title":"Exceptions swallowed by default","text":"<p>By default any exceptions thrown by a subscriber are swallowed by EventFlow after it has been logged as an error. Depending on the application this might be the preferred behavior, but in some cases it isn't. If a subscriber exception should be thrown, and thus allowing them to be caught in e.g. command handlers, the behaivor can be disabled by setting the <code>ThrowSubscriberExceptions</code> to <code>true</code> when configuring EventFlow.</p>"},{"location":"basics/subscribers/#asynchronous-subscribers","title":"Asynchronous subscribers","text":"<p>Asynchronous subscribers in EventFlow are executed using a scheduled job.</p> <p>Warning</p> <p>Asynchronous subscribers are disabled by default and must be enabled using the <code>IsAsynchronousSubscribersEnabled</code> configuration.</p> <p>Attention</p> <p>Since asynchronous subscribers are executed using a job, its important to configure proper job scheduling. The <code>EventFlow.Hangfire</code> NuGet  package integrates with the 'HangFire Job Scheduler https://www.hangfire.io,  and provides a usable solution to this requirement.</p> <p>The <code>ISubscribeAsynchronousTo&lt;,,&gt;</code> is shown here and is, besides its name, identical to its synchronous counterpart.</p> <pre><code>public interface ISubscribeAsynchronousTo&lt;TAggregate, in TIdentity, in TEvent&gt;\n  where TAggregate : IAggregateRoot&lt;TIdentity&gt;\n  where TIdentity : IIdentity\n  where TEvent : IAggregateEvent&lt;TAggregate, TIdentity&gt;\n{\n  Task HandleAsync(\n    IDomainEvent&lt;TAggregate, TIdentity, TEvent&gt; domainEvent,\n    CancellationToken cancellationToken);\n}\n</code></pre> <p>Danger</p> <p>Setting <code>ThrowSubscriberExceptions = true</code> has no effect on asynchronous subscribers.</p>"},{"location":"basics/subscribers/#subscribe-to-every-event","title":"Subscribe to every event","text":"<p>Instead of subscribing to every single domain, you can register an implementation of <code>ISubscribeSynchronousToAll</code> which is defined as shown here.</p> <pre><code>public interface ISubscribeSynchronousToAll\n{\n  Task HandleAsync(\n    IReadOnlyCollection&lt;IDomainEvent&gt; domainEvents,\n    CancellationToken cancellationToken);\n}\n</code></pre> <p>Any registered implementations will be notified for every domain event emitted.</p>"},{"location":"basics/subscribers/#rabbitmq","title":"RabbitMQ","text":"<p>See RabbitMQ setup for details on how to get started using RabbitMQ_.</p> <p>After RabbitMQ has been configured, all domain events are published to an exchange named <code>eventflow</code> with routing keys in the following format.</p> <pre><code>eventflow.domainevent.[Aggregate name].[Event name].[Event version]\n</code></pre> <p>Which will be the following for an event named <code>CreateUser</code> version <code>1</code> for the <code>MyUserAggregate</code>.</p> <pre><code>eventflow.domainevent.my-user.create-user.1\n</code></pre> <p>Note the lowercasing and adding of <code>-</code> whenever there's a capital letter.</p> <p>All the above is the default behavior. If you don't like it, replace the  registered message factory service <code>IRabbitMqMessageFactory</code> to  customize what routing key or exchange to use. Have a look at how <code>EventFlow &lt;https://github.com/rasmus/EventFlow&gt;</code>__ has done its implementation to get started.</p>"},{"location":"integration/event-stores/","title":"Event stores","text":"<p>By default, EventFlow uses an in-memory event store. However, EventFlow provides support for several alternatives.</p> <ul> <li>In-memory (for testing)</li> <li>Microsoft SQL Server</li> <li>MongoDB</li> <li>Redis</li> <li>Files (for testing)</li> </ul>"},{"location":"integration/event-stores/#in-memory","title":"In-memory","text":"<p>Attention</p> <p>The in-memory event store should not be used for production environments, only for testing purposes.</p> <p>Using the in-memory event store is easy as it's enabled by default, so there is no need to do anything.</p>"},{"location":"integration/event-stores/#mssql-event-store","title":"MSSQL event store","text":"<p>See MSSQL setup for details on how to get started using Microsoft SQL Server in EventFlow.</p> <p>To configure EventFlow to use MSSQL as the event store, simply add the <code>UseMssqlEventStore()</code> method as shown here.</p> <pre><code>IRootResolver rootResolver = EventFlowOptions.New\n  ...\n  .UseMssqlEventStore()\n  ...\n  .CreateResolver();\n</code></pre>"},{"location":"integration/event-stores/#create-and-migrate-required-mssql-databases","title":"Create and migrate required MSSQL databases","text":"<p>Before you can use the MSSQL event store, the required database and tables must be created. The database specified in your MSSQL connection will not be automatically created; you have to do this yourself.</p> <p>To make EventFlow create the required tables, execute the following code.</p> <pre><code>var msSqlDatabaseMigrator = rootResolver.Resolve&lt;IMsSqlDatabaseMigrator&gt;();\nEventFlowEventStoresMsSql.MigrateDatabase(msSqlDatabaseMigrator);\n</code></pre> <p>You should do this either on application start or preferably upon application install or update, e.g., when the website is installed.</p> <p>Attention</p> <p>If you utilize user permissions in your application, you need to grant the event writer access to the user-defined table type <code>eventdatamodel_list_type</code>. EventFlow uses this type to pass entire batches of events to the database.</p>"},{"location":"integration/event-stores/#postgresql-event-store","title":"PostgreSQL event store","text":"<p>The setup for PostgreSQL is similar to that of MSSQL. See PostgreSQL setup for setup documentation.</p>"},{"location":"integration/event-stores/#mongodb","title":"MongoDB","text":"<p>See MongoDB setup for details on how to get started using MongoDB in EventFlow.</p> <p>To configure EventFlow to use MongoDB as the event store, simply add the <code>UseMongoDbEventStore()</code> method as shown here.</p> <pre><code>IRootResolver rootResolver = EventFlowOptions.New\n  ...\n  .UseMongoDbEventStore()\n  ...\n  .CreateResolver();\n</code></pre>"},{"location":"integration/event-stores/#redis","title":"Redis","text":"<p>See Redis setup for details on how to get started using Redis and EventFlow. Ensure that your database is persistent.</p> <p>To configure EventFlow to use Redis as the event store, simply add the <code>UseRedisEventStore()</code> method as shown in the example below.</p> <pre><code>IRootResolver rootResolver = EventFlowOptions.New\n  ...\n  .UseRedisEventStore()\n  ...\n  .CreateResolver();\n</code></pre>"},{"location":"integration/event-stores/#files","title":"Files","text":"<p>Attention</p> <p>The Files event store should not be used for production environments, only for testing purposes.</p> <p>The file-based event store is useful if you have a set of events that represent a certain scenario and would like to create a test that verifies that the domain handles it correctly.</p> <p>To use the file-based event store, simply invoke <code>.UseFilesEventStore(\"...\")</code> with the path containing the files.</p> <pre><code>var storePath = @\"c:\\eventstore\";\nvar rootResolver = EventFlowOptions.New\n    ...\n    .UseFilesEventStore(FilesEventStoreConfiguration.Create(storePath))\n    ...\n    .CreateResolver();\n</code></pre>"},{"location":"integration/mongodb/","title":"Mongo DB","text":"<p>To setup EventFlow Mongo DB, install the NuGet package <code>EventFlow.MongoDB</code> and add this to your EventFlow setup.</p> <pre><code>// ...\n.ConfigureMongoDb(client, \"database-name\")\n// ...\n</code></pre> <p>After setting up Mongo DB support in EventFlow, you can continue to configure it.</p> <ul> <li>Event store</li> <li>Read model store</li> </ul>"},{"location":"integration/mssql/","title":"Microsoft SQL Server","text":"<p>To setup EventFlow Microsoft SQL Server integration, install the NuGet package <code>EventFlow.MsSql</code> and add this to your EventFlow setup.</p> <pre><code>public void ConfigureServices(IServiceCollection services)\n{\n  services.AddEventFlow(ef =&gt;\n  {\n    ef.ConfigureMsSql(MsSqlConfiguration.New\n      .SetConnectionString(@\"Server=.\\SQLEXPRESS;Database=MyApp;User Id=sa;Password=???\"))\n    .UseMsSqlEventStore();\n  });\n}\n</code></pre> <p>After setting up Microsoft SQL Server support in EventFlow, you can continue to configure it.</p> <ul> <li>Event store</li> <li>Read model store</li> </ul>"},{"location":"integration/postgresql/","title":"PostgreSQL","text":""},{"location":"integration/postgresql/#postgresql","title":"PostgreSQL","text":"<p>To setup EventFlow PostgreSQL integration, install the NuGet package EventFlow.PostgreSql and add this to your EventFlow setup.</p> <pre><code>// ...\n.ConfigurePostgreSql(PostgreSqlConfiguration.New\n  .SetConnectionString(@\"User ID=me;Password=???;Host=localhost;Port=5432;Database=MyApp\"))\n.UsePostgreSqlEventStore()\n.UsePostgreSqlSnapshotStore()\n.UsePostgreSqlReadModel&lt;UserReadModel&gt;()\n.UsePostgreSqlReadModel&lt;UserNicknameReadModel,UserNicknameReadModelLocator&gt;()\n// ...\n</code></pre> <p>This code block configures EventFlow to store events, snapshots and read models in PostgreSQL. It's not mandatory, you  can mix and match, i.e. storing events in PostgreSQL, read models in Elastic search and don't using snapshots at all.</p> <ul> <li>Event store. One big table <code>EventFlow</code> for all events for all aggregates.</li> <li>Read model store. Table <code>ReadModel-[ClassName]</code> per read model type. </li> <li>Snapshot store. One big table <code>EventFlowSnapshots</code> for all aggregates.</li> </ul>"},{"location":"integration/rabbitmq/","title":"RabbitMQ","text":"<p>To setup EventFlow's RabbitMQ integration, install the NuGet package <code>EventFlow.RabbitMQ</code> and add this to your EventFlow setup.</p> <pre><code>var uri = new Uri(\"amqp://localhost\");\n// ...\n.PublishToRabbitMq(RabbitMqConfiguration.With(uri))\n// ...\n</code></pre> <p>After setting up RabbitMQ support in EventFlow, you can continue to configure it.</p> <ul> <li>Publish all domain events</li> </ul>"},{"location":"integration/read-stores/","title":"Read model stores","text":"<p>In order to create query handlers that perform and enable them to search across multiple fields, read models or projections are used.</p> <p>To get started, you can use the built-in in-memory read model store, but EventFlow supports a few others as well.</p> <ul> <li>In-memory</li> <li>Microsoft SQL Server</li> <li>Elasticsearch</li> <li>MongoDB</li> <li>Redis</li> </ul>"},{"location":"integration/read-stores/#creating-read-models","title":"Creating read models","text":"<p>Read models are a flattened view of a subset or all aggregate domain events created specifically for efficient queries.</p> <p>Here's a simple example of how a read model for doing searches for usernames could look. The read model handles the <code>UserCreated</code> domain event to get the username and user ID.</p> <pre><code>public class UserReadModel : IReadModel,\n  IAmReadModelFor&lt;UserAggregate, UserId, UserCreated&gt;\n{\n  public string UserId { get; set; }\n  public string Username { get; set; }\n\n  public Task ApplyAsync(\n    IReadModelContext context,\n    IDomainEvent&lt;UserAggregate, UserId, UserCreated&gt; domainEvent,\n    CancellationToken cancellationToken)\n  {\n    UserId = domainEvent.AggregateIdentity.Value;\n    Username = domainEvent.AggregateEvent.Username.Value;\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>The read model applies all <code>UserCreated</code> events and thereby merely saves the latest value instead of the entire history, which makes it much easier to store in an efficient manner.</p>"},{"location":"integration/read-stores/#read-model-locators","title":"Read model locators","text":"<p>Typically, the ID of read models is the aggregate identity, but sometimes this isn't the case. Here are some examples.</p> <ul> <li>Items from a collection on the aggregate root</li> <li>Deterministic ID created from event data</li> <li>Entity within the aggregate</li> </ul> <p>To create read models in these cases, use the EventFlow concept of read model locators, which is basically a mapping from a domain event to a read model ID.</p> <p>As an example, consider if we could add several nicknames to a user. We might have a domain event called <code>UserNicknameAdded</code> similar to this.</p> <pre><code>public class UserNicknameAdded : AggregateEvent&lt;UserAggregate, UserId&gt;\n{\n  public Nickname Nickname { get; set; }\n}\n</code></pre> <p>We could then create a read model locator that would return the ID for each nickname we add via the event like this.</p> <pre><code>public class UserNicknameReadModelLocator : IReadModelLocator\n{\n  public IEnumerable&lt;string&gt; GetReadModelIds(IDomainEvent domainEvent)\n  {\n    var userNicknameAdded = domainEvent as\n      IDomainEvent&lt;UserAggregate, UserId, UserNicknameAdded&gt;;\n    if (userNicknameAdded == null)\n    {\n      yield break;\n    }\n\n    yield return userNicknameAdded.Nickname.Id;\n  }\n}\n</code></pre> <p>And then use a read model similar to this that represents each nickname.</p> <pre><code>public class UserNicknameReadModel : IReadModel,\n  IAmReadModelFor&lt;UserAggregate, UserId, UserNicknameAdded&gt;\n{\n  public string UserId { get; set; }\n  public string Nickname { get; set; }\n\n  public Task ApplyAsync(\n    IReadModelContext context,\n    IDomainEvent&lt;UserAggregate, UserId, UserNicknameAdded&gt; domainEvent,\n    CancellationToken cancellationToken)\n  {\n    UserId = domainEvent.AggregateIdentity.Value;\n    Nickname = domainEvent.AggregateEvent.Nickname.Value;\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>You may need to assign the ID of your read model from a batch of nicknames assigned on the creation event of the username. You would then read the assigned read model ID acquired from the locator using the 'context' field:</p> <pre><code>public class UserNicknameReadModel : IReadModel,\n  IAmReadModelFor&lt;UserAggregate, UserId, UserCreatedEvent&gt;\n{\n  public string Id { get; set; }\n  public string UserId { get; set; }\n  public string Nickname { get; set; }\n\n  public Task ApplyAsync(\n    IReadModelContext context,\n    IDomainEvent&lt;UserAggregate, UserId, UserCreatedEvent&gt; domainEvent,\n    CancellationToken cancellationToken)\n  {\n    var id = context.ReadModelId;\n    UserId = domainEvent.AggregateIdentity.Value;        \n    var nickname = domainEvent.AggregateEvent.Nicknames.Single(n =&gt; n.Id == id);\n\n    Id = nickname.Id;\n    Nickname = nickname.Nickname;\n    return Task.CompletedTask;\n  }\n}\n</code></pre> <p>We could then use this nickname read model to query all the nicknames for a given user by searching for read models that have a specific <code>UserId</code>.</p>"},{"location":"integration/read-stores/#read-store-implementations","title":"Read store implementations","text":"<p>EventFlow has built-in support for several different read model stores.</p>"},{"location":"integration/read-stores/#in-memory","title":"In-memory","text":"<p>Attention</p> <p>In-memory event store shouldn't be used for production environments, only for tests.</p> <p>The in-memory read store is easy to use and easy to configure. All read models are stored in-memory, so if EventFlow is restarted, all read models are lost.</p> <p>To configure the in-memory read model store, simply call <code>UseInMemoryReadStoreFor&lt;&gt;</code> or <code>UseInMemoryReadStoreFor&lt;,&gt;</code> with your read model as the generic argument.</p> <pre><code>public void ConfigureServices(IServiceCollection services)\n{\n  services.AddEventFlow(ef =&gt;\n  {\n    ef.UseInMemoryReadStoreFor&lt;UserReadModel&gt;();\n    ef.UseInMemoryReadStoreFor&lt;UserNicknameReadModel, UserNicknameReadModelLocator&gt;();\n  });\n}\n</code></pre>"},{"location":"integration/read-stores/#microsoft-sql-server","title":"Microsoft SQL Server","text":"<p>To configure the MSSQL read model store, simply call <code>UseMssqlReadModel&lt;&gt;</code> or <code>UseMssqlReadModel&lt;,&gt;</code> with your read model as the generic argument.</p> <pre><code>// ...\n.UseMssqlReadModel&lt;UserReadModel&gt;()\n.UseMssqlReadModel&lt;UserNicknameReadModel,UserNicknameReadModelLocator&gt;()\n// ...\n</code></pre> <p>By convention, EventFlow uses the table named <code>ReadModel-[CLASS NAME]</code> as the table to store the read model rows in. If you need to change this, use the <code>Table</code> from the <code>System.ComponentModel.DataAnnotations.Schema</code> namespace. So in the above example, the read model <code>UserReadModel</code> would be stored in a table called <code>ReadModel-UserReadModel</code> unless stated otherwise.</p> <p>To allow EventFlow to find the read models stored, a single column is required to have the <code>MsSqlReadModelIdentityColumn</code> attribute. This will be used to store the read model ID.</p> <p>You should also create an <code>int</code> column that has the <code>MsSqlReadModelVersionColumn</code> attribute to tell EventFlow which column the read model version is stored in.</p> <p>Attention</p> <p>EventFlow expects the read model to exist, and thus any maintenance of the database schema for the read models must be handled before EventFlow is initialized. Or, at least before the read models are used in EventFlow.</p>"},{"location":"integration/read-stores/#elasticsearch","title":"Elasticsearch","text":"<p>To configure the <code>Elasticsearch &lt;https://www.elastic.co/products/elasticsearch&gt;</code>__ read model store, simply call <code>UseElasticsearchReadModel&lt;&gt;</code> or <code>UseElasticsearchReadModel&lt;,&gt;</code> with your read model as the generic argument.</p> <pre><code>// ...\n.ConfigureElasticsearch(new Uri(\"http://localhost:9200/\"))\n// ...\n.UseElasticsearchReadModel&lt;UserReadModel&gt;()\n.UseElasticsearchReadModel&lt;UserNicknameReadModel,UserNicknameReadModelLocator&gt;()\n// ...\n</code></pre> <p>Overloads of <code>ConfigureElasticsearch(...)</code> are available for alternative Elasticsearch configurations.</p> <p>Attention</p> <p>Make sure to create any mapping the read model requires in Elasticsearch before using the read model in EventFlow.</p> <p>If EventFlow receives a request to purge a specific read model, it does it by deleting the index. This means that a separate index should be created for each read model.</p> <p>If you want to control the index a specific read model is stored in, create an implementation of <code>IReadModelDescriptionProvider</code> and register it in the service collection.</p>"},{"location":"integration/read-stores/#mongodb","title":"MongoDB","text":"<p>To configure the MongoDB read model store, call <code>UseMongoDbReadModel&lt;&gt;</code> or <code>UseMongoDbReadModel&lt;,&gt;</code> with your read model as the generic argument.</p> <pre><code>// ...\n.UseMongoDbReadModel&lt;UserReadModel&gt;()\n.UseMongoDbReadModel&lt;UserNicknameReadModel,UserNicknameReadModelLocator&gt;()\n// ...\n</code></pre>"},{"location":"integration/read-stores/#redis","title":"Redis","text":"<p>To configure Redis as a read model store, call <code>UseRedisReadModel&lt;&gt;</code> or <code>UseRedisReadModel&lt;,&gt;</code> with your read model and optionally the ReadModelLocator as the generic argument.</p> <p>In order to use Redis as your read model store, you need to enable the Redis Search and Redis JSON modules, both of which are included in Redis Stack.</p> <pre><code>// ...\n.UseRedisReadModel&lt;UserReadModel&gt;()\n.UseRedisReadModel&lt;UserNicknameReadModel,UserNicknameReadModelLocator&gt;()\n// ...\n</code></pre> <p><code>EventFlow.Redis</code> uses Redis OM to provide a LINQ-like querying experience.  Keep in mind that in order to query a read model by a field other than the ID, you have to add the <code>[Indexed]</code> attribute to the field. For more information, check the Redis OM documentation.</p>"},{"location":"integration/redis/","title":"Redis","text":""},{"location":"integration/redis/#persistence","title":"Persistence","text":"<p>In order to use Redis as a primary database for events and read models, some sort of persistence option should be used. Redis provides several configurable options.</p>"},{"location":"integration/redis/#version-and-modules","title":"Version and modules","text":"<p>In order to use Redis as an event store, Redis version 5 is required in order to use streams. The read and snapshot store require the Redis Search and JSON modules, which are included in Redis Stack.</p>"},{"location":"integration/redis/#setup","title":"Setup","text":"<p>To setup Redis together with EventFlow, install the NuGet package <code>EventFlow.Redis</code> and add <code>.ConfigureRedis(connectionString)</code> or <code>.ConfigureRedis(IConnectionMultiplexer)</code> to your <code>EventFlowOptions</code> configuration.</p> <p>After the setup, you can configure Redis as your EventStore, ReadStore and SnapshotStore.</p> <ul> <li>Event store</li> <li>Read model store</li> </ul>"},{"location":"migrations/v0-to-v1/","title":"Migration guide 0.x to 1.x","text":"<p>EventFlow version 1 introduces carefully considered breaking API changes. Traditionally EventFlow has a strict policy regarding stable APIs, with the introduction of the 1 release, it is the first time any breaking change has been made to the public API surface.</p> <p>Here is the general motivation for introducing breaking changes to EventFlow.</p> <ul> <li>The initial version of EventFlow had its own IoC and logger implementation,   but with the introduction of the standardized <code>Microsoft.Extensions</code> packages,   EventFlow's custom implementations are removed</li> <li>Focus on LTS versions of .NET (Core) and remove support .NET Framework as many   of the new C# language features are not available here</li> <li>Fix misspelled API</li> <li>Add obviously missing async/await on critical methods</li> <li>Remove non-async methods wrapper methods related to the bundled <code>AsyncHelper</code></li> </ul>"},{"location":"migrations/v0-to-v1/#data-in-event-stores","title":"Data in event stores","text":"<p>Upgrading EventFlow should never break existing data in event stores, not even between major versions. All data currently in event stores will work with 1.x releases. However, it might not be possible to do a rollback from 1.x to 0.x.</p>"},{"location":"migrations/v0-to-v1/#recommended-strategy-for-migrating-0x-to-1x","title":"Recommended strategy for migrating 0.x to 1.x","text":"<p>Here are a few recommendations that might be useful when planning the migration of EventFlow from 0.x to 1.x. </p> <ul> <li>Since there is no change to the underlying storage, creating a release that   only has EventFlow upgraded is highly recommended. This enables easy rollback   if you encounter unexpected problems. Do note that rollback is not guaranteed   to work safely, but should work. Please test it before proceeding with an   upgrade</li> <li>Since the <code>IEventUpgrader&lt;,&gt;</code> has changed significantly, consider using the new   base class <code>EventUpgraderNonAsync</code> in any existing upgraders. It provides an   <code>abstract</code> method with the same signature as the old interface that can be   overridden, making the switch significantly easier</li> </ul>"},{"location":"migrations/v0-to-v1/#notable-new-features-in-version-1","title":"Notable new features in version 1","text":"<p>While the main focus of version 1 is to bring EventFlow up to speed with the latest standards, there are some changes/features that have been added as well. Features that were not possible to add before as introducing them would cause breaking changes.</p>"},{"location":"migrations/v0-to-v1/#multiple-mssql-connection-strings","title":"Multiple MSSQL connection strings","text":"<p>It is now possible to have read models outside the main database by adding a <code>[SqlReadModelConnectionStringName]</code> attribute to the read models. The named connection string is then used for that read model. To configure the named connection strings, provide them during the initial configuration.</p> <pre><code>MsSqlConfiguration.New\n  .SetConnectionString(/* events connection string */)\n  .SetConnectionString(\"my-awesome-read-model\", /* alternative connection string */)\n</code></pre> <p>If the connection string is not known at initialization, provide your own instance of the <code>IMsSqlConfiguration</code> which now has a new method that allows reading connection strings at runtime.</p> <pre><code>  Task&lt;string&gt; GetConnectionStringAsync(\n    Label label,\n    string name,\n    CancellationToken cancellationToken);\n</code></pre> <p>This allows for connection strings to be fetched runtime from external sources.</p>"},{"location":"migrations/v0-to-v1/#event-upgraders-are-now-async-and-work-with-the-read-model-populator","title":"Event upgraders are now async and work with the read model populator","text":"<p>In version 0.x, event upgraders aren't applied when events are loaded and re-populated to read models using the <code>IReadModelPopulator</code>. This is fixed for version 1.x, which properly will require some change to upgraders if the re-population feature is used.</p>"},{"location":"migrations/v0-to-v1/#changes-to-supported-net-versions","title":"Changes to supported .NET versions","text":"<p>With the version 1 release, EventFlow limits the number of supported .NET versions, to that of official .NET (Core) LTS versions. Support for non-LTS versions will be limited, but do expect to have EventFlow lag a little behind when cutting support on older versions.</p> <p>As of the 1.0 release, EventFlow supports the following framework versions.</p> <ul> <li><code>netstandard2.1</code></li> <li><code>netcoreapp3.1</code></li> <li><code>net6.0</code></li> <li><code>net8.0</code></li> </ul> <p>Note that this enabled the use of <code>IAsyncEnumerable</code> which is going to be a key driver for some of the upcoming features of EventFlow. </p>"},{"location":"migrations/v0-to-v1/#nuget-packages-removed","title":"NuGet packages removed","text":"<p>With the move toward the standardized Microsoft extensions packages and removal of support for .NET Framework, there are a few NuGet packages that will no longer be supported.</p> <ul> <li><code>EventFlow.Autofac</code></li> </ul> <p>Since EventFlow uses the new <code>Microsoft.Extensions.DependencyInjection</code> for    handling IoC, it's possible to install the Autofac adapter package instead,    thus rendering the package obsolete.</p> <ul> <li><code>EventFlow.DependencyInjection</code></li> </ul> <p>Since the standard dependency injection is now a first class citizen in the   core package, this package is no longer needed.</p> <ul> <li><code>EventFlow.Owin</code></li> </ul> <p>OWIN support has been removed as ASP.NET Core is introduced.</p>"},{"location":"migrations/v0-to-v1/#aligning-with-microsoft-extension-packages","title":"Aligning with Microsoft extension packages","text":"<p>Several types have been removed from EventFlow in order to align with the Microsoft extension packages.</p> <ul> <li><code>ILog</code> use <code>ILogger</code> from <code>Microsoft.Extensions.Logger.Abstractions</code></li> <li><code>IResolver</code> use <code>IServiceProvider</code>   from <code>Microsoft.Extensions.DependencyInjection.Abstractions</code></li> </ul>"},{"location":"migrations/v0-to-v1/#only-one-interface-for-read-models","title":"Only one interface for read models","text":"<p>The interfaces <code>IAmAsyncReadModelFor</code> have replaced the original <code>IAmReadModelFor</code> leaving only async interface to implement on read models.</p> <p>Originally EventFlow only had the non-async version <code>IAmReadModelFor</code>, but as it became evident that updating read models sometimes requires the invocation of  async method, the interface <code>IAmAsyncReadModelFor</code> was introduced as not to create any breaking changes. Now, we remove the one and only have one interface to implement.</p>"},{"location":"migrations/v0-to-v1/#removal-of-non-async-method","title":"Removal of non-async method","text":"<p>Several non-async methods have been removed as well as the <code>EventFlow.Core.AsyncHelper</code> which was used to implement these methods without introducing deadlocks when running in some .NET Framework environments.</p> <ul> <li><code>IAggregateStore.Load</code></li> <li><code>IAggregateStore.Store</code></li> <li><code>IAggregateStore.Update</code></li> <li><code>ICommandBus.Publish</code></li> <li><code>IEventStore.LoadAggregate</code></li> <li><code>IEventStore.LoadEvents</code></li> <li><code>IEventStore.LoadAllEvents</code></li> <li><code>IQueryProcessor.Process</code></li> <li><code>IReadModelPopulator.Populate</code></li> <li><code>IReadModelPopulator.Purge</code></li> </ul>"},{"location":"migrations/v0-to-v1/#initializing-eventflow","title":"Initializing EventFlow","text":"<p>Starting version 1, there are a few ways you can initialize EventFlow.</p>"},{"location":"migrations/v0-to-v1/#fluent-as-iservicecollection-extension","title":"Fluent as <code>IServiceCollection</code> extension","text":"<pre><code>serviceCollection.AddEventFlow(o =&gt; \n    // Set up EventFlow here\n    );\n</code></pre>"},{"location":"migrations/v0-to-v1/#traditionally-passing-a-iservicecollection-reference","title":"Traditionally passing a <code>IServiceCollection</code> reference","text":"<pre><code>var eventFlowOptions = EventFlowOptions.New(serviceCollection)\n\n// Set up EventFlow here\n</code></pre>"},{"location":"migrations/v0-to-v1/#let-eventflow-create-the-iservicecollection","title":"Let EventFlow create the <code>IServiceCollection</code>","text":"<p>Useful in small tests, but should NOT be used in production setups.</p> <pre><code>var eventFlowOptions = EventFlowOptions.New()\n// its a short hand for\n// var eventFlowOptions = EventFlowOptions.New(new ServiceCollection())\n\n// Set up EventFlow here\n</code></pre>"}]}